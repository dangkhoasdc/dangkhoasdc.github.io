<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Programmings on Dang-Khoa&#39;s blog </title>
    <link>http://dangkhoasdc.github.io/programming/</link>
    <description>Recent content in Programmings on Dang-Khoa&#39;s blog </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Dang-Khoa</copyright>
    <atom:link href="/programming/" rel="self" type="application/rss+xml" />
    
    <item>
      <title></title>
      <link>http://dangkhoasdc.github.io/programming/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://dangkhoasdc.github.io/programming/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://dangkhoasdc.github.io/programming/randomized-algs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://dangkhoasdc.github.io/programming/randomized-algs/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Các ví dụ về thuật toán ngẫu nhiên – Dang-Khoa – A computer vision and programming blog.&lt;/title&gt;

        &lt;meta charset=&#34;utf-8&#34; /&gt;
    &lt;meta content=&#39;text/html; charset=utf-8&#39; http-equiv=&#39;Content-Type&#39;&gt;
    &lt;meta http-equiv=&#39;X-UA-Compatible&#39; content=&#39;IE=edge&#39;&gt;
    &lt;meta name=&#39;viewport&#39; content=&#39;width=device-width, initial-scale=1.0, maximum-scale=1.0&#39;&gt;

    
    &lt;meta name=&#34;description&#34; content=&#34;Tiếp tục seri về thuật toán ngẫu nhiên, trong bài viết này mình ghi lại 3 ví dụ điển hình trong họ bài toán này. Tất cả các ví dụ đều nằm trong cuốn sách Randomized Algorithms

&#34; /&gt;
    &lt;meta property=&#34;og:description&#34; content=&#34;Tiếp tục seri về thuật toán ngẫu nhiên, trong bài viết này mình ghi lại 3 ví dụ điển hình trong họ bài toán này. Tất cả các ví dụ đều nằm trong cuốn sách Randomized Algorithms

&#34; /&gt;
    
    &lt;meta name=&#34;author&#34; content=&#34;Dang-Khoa&#34; /&gt;

    
    &lt;meta property=&#34;og:title&#34; content=&#34;Các ví dụ về thuật toán ngẫu nhiên&#34; /&gt;
    &lt;meta property=&#34;twitter:title&#34; content=&#34;Các ví dụ về thuật toán ngẫu nhiên&#34; /&gt;
    

    &lt;!--[if lt IE 9]&gt;
      &lt;script src=&#34;http://html5shiv.googlecode.com/svn/trunk/html5.js&#34;&gt;&lt;/script&gt;
    &lt;![endif]--&gt;

    &lt;link rel=&#34;stylesheet&#34; type=&#34;text/css&#34; href=&#34;http://dangkhoasdc.github.io/style.css&#34; /&gt;
    &lt;link rel=&#34;alternate&#34; type=&#34;application/rss+xml&#34; title=&#34;Dang-Khoa - A computer vision and programming blog.&#34; href=&#34;http://dangkhoasdc.github.io/feed.xml&#34; /&gt;

    &lt;!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now --&gt;
    &lt;script type=&#34;text/x-mathjax-config&#34;&gt;
  MathJax.Hub.Config({
    extensions: [&#34;tex2jax.js&#34;],
    jax: [&#34;input/TeX&#34;, &#34;output/HTML-CSS&#34;],
    tex2jax: {
      inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&#34;\\(&#34;,&#34;\\)&#34;] ],
      displayMath: [ [&#39;$$&#39;,&#39;$$&#39;], [&#34;\\[&#34;,&#34;\\]&#34;] ],
      processEscapes: true
    },
    &#34;HTML-CSS&#34;: { availableFonts: [&#34;TeX&#34;] }
  });
&lt;/script&gt;
    &lt;script src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34; type=&#34;text/javascript&#34;&gt;&lt;/script&gt;

  &lt;/head&gt;

  &lt;body&gt;
    &lt;div class=&#34;wrapper-masthead&#34;&gt;
      &lt;div class=&#34;container&#34;&gt;
        &lt;header class=&#34;masthead clearfix&#34;&gt;
          &lt;a href=&#34;http://dangkhoasdc.github.io/&#34; class=&#34;site-avatar&#34;&gt;&lt;img src=&#34;http://dangkhoasdc.github.io/images/icon_512.png&#34; /&gt;&lt;/a&gt;

          &lt;div class=&#34;site-info&#34;&gt;
            &lt;h1 class=&#34;site-name&#34;&gt;&lt;a href=&#34;http://dangkhoasdc.github.io/&#34;&gt;Dang-Khoa&lt;/a&gt;&lt;/h1&gt;
            &lt;p class=&#34;site-description&#34;&gt;A computer vision and programming blog.&lt;/p&gt;
          &lt;/div&gt;

          &lt;nav&gt;
            &lt;a href=&#34;http://dangkhoasdc.github.io/&#34;&gt;Blog&lt;/a&gt;
            &lt;a href=&#34;http://dangkhoasdc.github.io/pages/about/&#34;&gt;About&lt;/a&gt;
          &lt;/nav&gt;
        &lt;/header&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div id=&#34;main&#34; role=&#34;main&#34; class=&#34;container&#34;&gt;
      &lt;article class=&#34;post&#34;&gt;
  &lt;h1&gt;Các ví dụ về thuật toán ngẫu nhiên&lt;/h1&gt;

  &lt;div class=&#34;entry&#34;&gt;
    &lt;p&gt;Tiếp tục seri về thuật toán ngẫu nhiên, trong bài viết này mình ghi lại 3 ví dụ điển hình trong họ bài toán này. Tất cả các ví dụ đều nằm trong cuốn sách &lt;a href=&#34;https://www.amazon.com/Randomized-Algorithms-Rajeev-Motwani/dp/0521474655&#34;&gt;Randomized Algorithms&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;randomized-quicksort&#34;&gt;Randomized Quicksort&lt;/h1&gt;

&lt;p&gt;Thuật toán quicksort có lẽ là một trong những thuật toán khá dễ hiểu khi tìm hiểu về các thuật toán ngẫu nhiên. Thử tưởng tượng ta cho quicksort thông thường chạy 10 lần với dữ liệu đã sắp xếp với randomized-quicksort cũng với cấu hình như vậy, ta sẽ thấy sự khác biệt lớn.&lt;/p&gt;

&lt;h2 id=&#34;thut-ton&#34;&gt;Thuật toán&lt;/h2&gt;

&lt;script src=&#34;https://gist.github.com/dangkhoasdc/e7ad5caa46b7bad12ae4f5ff221d707d.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;chng-minh&#34;&gt;Chứng minh&lt;/h2&gt;

&lt;p&gt;Cho dữ liệu đầu vào gồm $n$ phần tử khác nhau. Gọi $S_i, 1 \leq i \leq n$ là phần tử &lt;em&gt;rank i&lt;/em&gt; (phần tử nhỏ thứ &lt;em&gt;i&lt;/em&gt;) trong mảng, đồng thời ta có $X_{ij}$ biến ngẫu nhiên bằng $1$ nếu xuất hiện phép so sánh của 2 phần tử $S_i$ và $S_j$ trong quá trình thực thi, bằng không nếu không xuất hiện phép so sánh nào.&lt;/p&gt;

&lt;p&gt;Như vậy, độ phức tạp của &lt;code class=&#34;highlighter-rouge&#34;&gt;randomized-quicksort&lt;/code&gt; được tính thông qua quá trình sắp xếp mảng theo pivot mà chi phí chính nằm ở phép so sánh các phần tử, tổng chi phí chính là $\sum_{i=1}^n \sum_{j&amp;gt;i} X_{ij}$.&lt;/p&gt;

&lt;p&gt;Tuy nhiên, điều ta quan tâm hơn ở đây là &lt;em&gt;kì vọng&lt;/em&gt; chi phí trong các lần thực thi:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;E \left [ \sum_{i=1}^n \sum_{j&gt;i} X_{ij} \right ] = \sum_{i=1}^n \sum_{j&gt;i} E[X_{ij}]&lt;/script&gt;

&lt;p&gt;Công thức trên được xây dựng dựa vào một tính chất của kì vọng: &lt;a href=&#34;https://brilliant.org/wiki/linearity-of-expectation/&#34;&gt;tính tuyến tính của kì vọng&lt;/a&gt;. Như vậy kì vọng của tổng các chi phí so sánh chính bằng tổng của từng kì vọng của biến ngẫu nhiên $X_{ij}$. Gọi $p_{ij}$ là xác suất để $X_{ij}=1$. Ta có:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;E[X_{ij}] = p_{ij} * 1 + (1-p) * 0 = p_ij&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;E \left [ \sum_{i=1}^n \sum_{j&gt;i} X_{ij} \right ] = \sum_{i=1}^n \sum_{j&gt;i} p_{ij}&lt;/script&gt;

&lt;p&gt;Bài toán được qui về việc tính xác suất khi nào phép so sánh giữa hai phần tử $S_i$ và $S_j$ xuất hiện.&lt;/p&gt;

&lt;p&gt;Nếu ta xem quá trình thực thi của &lt;code class=&#34;highlighter-rouge&#34;&gt;randomized-quicksort&lt;/code&gt; là quá trình xây dựng cây nhị phân: với mỗi node chính là 1 pivot tại thời điểm gọi hàm &lt;code class=&#34;highlighter-rouge&#34;&gt;partition&lt;/code&gt;, kết quả hàm &lt;code class=&#34;highlighter-rouge&#34;&gt;partition&lt;/code&gt; ta có được 2 cây con bên trái và phải của node pivot dùng để so sánh. Nếu $S_i$ và $S_j$ nằm ở hai nhánh con trái-phải thì phép so sánh giữa hai phần tử này chắc chắn không xảy ra. Như vậy $S_i$ và $S_j$ có quan hệ cha con - một trong hai phần tử phải thuộc node cấp lớn hơn của node kia. Một giả thuyết khác cần xem xét đó là xác suất các số được chọn làm pivot phải bằng nhau (uniform distribution) - có được giả thuyết này ta mới tính được độ phức tạp trong thời gian trung bình được.&lt;/p&gt;

&lt;p&gt;Như vậy, để $X_{ij}=1$ khi và chỉ khi một trong hay vị trí $S_i$ hoặc $S_j$ được chọn, và đó là $p_{ij} = \frac{2}{j - i + 1} $ (Xác suất này được tính khi loại đi xác suất chọn phải những pivot nằm bên trái của $S_i$ hoặc nằm bên phải của $S_j$)&lt;/p&gt;

&lt;p&gt;Như vậy ta có:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;E \left [ \sum_{i=1}^n \sum_{j&gt;i} X_{ij} \right ] =  \sum_{i=1}^n \sum_{j&gt;i} \frac{2}{j - i + 1}&lt;/script&gt;

&lt;p&gt;Đặt $k = j - i + 1$, ta được:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\sum_{i=1}^n \sum_{j&gt;i} p_{ij} \leq \sum_{i=1}^n \sum_{k=1}^{n-i+1} \frac{1}{k}&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\leq 2 \sum_{i=1}^n \sum_{k=1}^{n} \frac{1}{k}&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;= 2n \sum_{k=1}^{n} \frac{1}{k}&lt;/script&gt;

&lt;p&gt;$\sum_{k=1}^{n} \frac{1}{k}$ chính là &lt;a href=&#34;https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)#Rate_of_divergence&#34;&gt;chuỗi harmony&lt;/a&gt; và tổng này sẽ hội tụ về xấp xỉ của $ln(n)$. Và như vậy&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;E \left [ \sum_{i=1}^n \sum_{j&gt;i} X_{ij} \right ] \leq 2nlogn&lt;/script&gt;

&lt;h1 id=&#34;random-mincut&#34;&gt;Random Mincut&lt;/h1&gt;

&lt;h2 id=&#34;v-d&#34;&gt;Ví dụ&lt;/h2&gt;

&lt;p&gt;Giả sử ta có dữ liệu facebook của đám bạn cấp 3 và đang tò mò xem trong chục năm qua, những đứa bạn đó có lập thành nhóm chơi thân nào không. Dữ liệu đầu vào là danh sách các bạn trong lớp cấp 3 và mỗi quan hệ từng người với nhau (quan hệ bạn cấp 3, bạn đại học, đồng nghiệp, quan hệ nam nữ, vợ chồng).&lt;/p&gt;

&lt;p&gt;Giả sử ta tạo một đồ thị với đỉnh là một người trong lớp, &lt;code class=&#34;highlighter-rouge&#34;&gt;a&lt;/code&gt; có thể nối với &lt;code class=&#34;highlighter-rouge&#34;&gt;b&lt;/code&gt; thông qua các cạnh nối:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bạn cấp 3 (cái này chắc chắn)&lt;/li&gt;
  &lt;li&gt;Bạn đại học&lt;/li&gt;
  &lt;li&gt;Đồng nghiệp&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Việc tìm ra nhóm bạn &lt;em&gt;thân&lt;/em&gt; - tức gắng bó với nhau sau thời gian cấp 3 chính là việc tìm cách tách đồ thị lớn này thành những đồ thị con.&lt;/p&gt;

&lt;p&gt;Những bài toán &lt;em&gt;chia cắt&lt;/em&gt; đồ thị gọi là &lt;em&gt;graph cut&lt;/em&gt;, nếu trong bài toán yêu cầu tìm ra đoạn cắt nào có chi phí thấp nhất: cắt ít số cạnh nhất - thì đó chính là bài toán tìm &lt;em&gt;mincut&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Trong ví dụ này ta xét đồ thị là một &lt;a href=&#34;http://mathworld.wolfram.com/Multigraph.html&#34;&gt;multigraph&lt;/a&gt; - tức đồ thị có thể có nhiều cạnh cùng nối chung hai điểm. Một số định nghĩa cho phép &lt;em&gt;multigraph&lt;/em&gt; là đồ thị có các cạnh lặp (self-loop). Để thuận tiện cho việc chứng minh và minh hoạ, các đồ thị được đề cập trong bài là các đồ thị vô hướng.&lt;/p&gt;

&lt;h2 id=&#34;karger-mincuthttpsenwikipediaorgwikikarger27salgorithm&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Karger%27s_algorithm&#34;&gt;Karger Mincut&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/e/e7/Single_run_of_Karger%E2%80%99s_Mincut_algorithm.svg&#34; alt=&#34;Minh hoạ thuật toán Karger&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Một quá trình quan trọng trong thuật toán Karger là &lt;em&gt;Edge Contraction&lt;/em&gt; - gộp cạnh. Cho một cạnh $ e = \{u, v\}$, sau phép gộp cạnh ta sẽ có được một &lt;em&gt;đỉnh&lt;/em&gt; mới là $uv$ trong đó tất cả các cạnh nối từ $u$ đến $v$ hay ngược lại đều bị loại bỏ, đồng thời các cạnh lặp (self-loop) cũng bị xoá bỏ.&lt;/p&gt;

&lt;p&gt;Với các cạnh khác $ e’ = \{u, w\}$ hay $e’=\{v, w\}$ đều trở thành $e’=\{uv,w\}$.&lt;/p&gt;

&lt;p&gt;Một cách đơn giản: phép gộp cạnh sẽ nhập 2 đỉnh lại với nhau - xoá toàn bộ các cạnh nối 2 cạnh cũ và giữ lại những cạnh nối 2 đỉnh đó với các đỉnh khác trong đồ thị.&lt;/p&gt;

&lt;p&gt;Thuật toán được mô tả như sau:&lt;/p&gt;

&lt;div class=&#34;highlighter-rouge&#34;&gt;&lt;pre class=&#34;highlight&#34;&gt;&lt;code&gt;1. Chọn ngẫu nhiên (theo phân phối đều) một cạnh trong đồ thị.
2. Thực hiện phép gộp cạnh vừa chọn.
3. Lặp lại bước (1) cho đến khi số đỉnh trong đồ thị còn lại 2.
4. Output: min-cut là các cạnh còn lại trong đồ thị
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&#34;tnh-ng-ng-ca-gii-thut&#34;&gt;Tính đúng đắng của giải thuật&lt;/h2&gt;

&lt;p&gt;Để có thể tính được độ phức tạp trong thời gian trung bình, ta cần quay lại một chút về các tính chất của đồ thị. Cho đa đồ thị (multigraph) $G=(V, E)$ gồm các đỉnh $V$ và các cạnh $E$. Gọi $d(v)$ là bậc của đỉnh $v$ là tổng số các cạnh liên thuộc với $v$. Ta có tính chất sau:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\sum_{v \in V} d(v) = 2 | E |&lt;/script&gt;

&lt;p&gt;Gọi $C$ là lát cắt có kích thước nhỏ nhất $k$ - tức số lượng các cạnh trong lát cắt đó là $k$. Do đó, bậc tối thiểu của mỗi cạnh trong đồ thị này là $k$. Bởi nếu tồn tại một đỉnh có bậc nhỏ hơn $k$ thì lắt cắt $k$ không phải là lát cắt nhỏ nhất.&lt;/p&gt;

&lt;p&gt;Như vậy ta có:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;nk \leq \sum_{v \in V} d(v) = 2 | E |&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;|E| \geq \frac{nk}{2}&lt;/script&gt;

&lt;p&gt;Ta thấy xác suất để thuật toán gộp cạnh chọn đúng ngay 1 cạnh trong C chính là&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\frac{k}{|E|}&lt;/script&gt;

&lt;p&gt;kết hợp với bất đẳng thức phía trên, ta được:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\frac{k}{|E|} \leq \frac{2k}{nk} = \frac{2}{n}&lt;/script&gt;

&lt;p&gt;Như vậy, xác suất để thuật toán gộp cạnh không chọn phải các cạnh của $C$ là $p_n $.&lt;/p&gt;

&lt;p&gt;Ta có $p_n \leq (1-\frac{2}{n})p_{n-1} $ .&lt;/p&gt;

&lt;p&gt;Đồng thời ta cũng có $ p_2 = 1 $ lí do là bởi Karger chỉ chọn cạnh để gộp khi $ \vert V \vert &amp;gt; 2 $&lt;/p&gt;

&lt;p&gt;Nên khi $ n=2 $ thì biến cố chọn phải cạnh để gộp nằm trong $ C $ chắc chắn không xảy ra.&lt;/p&gt;

&lt;p&gt;Xác suất $p_n$ có cận như sau:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;p_n \geq \prod_{i=0}^{n-3} \left (1 - \frac{2}{n-i} \right ) = \frac{2}{n(n-1)}&lt;/script&gt;

&lt;p&gt;Để dễ tưởng tượng hơn, ta có thể phân tích một chút về trường hợp Karger không tìm ra được mincut, rõ ràng xác suất đó chính là $ 1 - \frac{2}{n(n-1)}$, để tăng độ chính xác, ta có thể cho Karger chạy $k$ lần. Lúc này, xác suất Karger không tìm ra được mincut là: $ \left (1 - \frac{2}{n(n-1)} \right )^k$. Có một bất đẳng thức thú vị ở đây:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\frac{1}{4} \leq \left (1 - \frac{1}{x} \right )^ x \leq \frac{1}{e}&lt;/script&gt;

&lt;p&gt;Giả sử $k = \frac{n(n-1)}{2}\ln n$ ta có được kết quả khá đẹp như sau:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\left (1 - \frac{2}{n(n-1)} \right )^{\frac{n(n-1)}{2}\ln n} \leq \left (\frac{1}{e} \right )^{\frac{n(n-1)}{2}\ln n} = \left (\frac{1}{e} \right ) ^{\ln n} = \frac{1}{n}&lt;/script&gt;

&lt;h1 id=&#34;binary-planar-partitions&#34;&gt;Binary Planar Partitions&lt;/h1&gt;

&lt;h2 id=&#34;gii-thiu&#34;&gt;Giới thiệu&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/cGwRyxq.png&#34; alt=&#34;Một ví dụ về cây BSP&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Binary Planar Partitions (trong trường hợp tổng quát là &lt;em&gt;Binary Space Partitions&lt;/em&gt;) là một phương pháp phổ biến được sử dụng nhằm chia cắt không gian thành các tập lồi (convex set) chứa các siêu phẳng - hyperplane. Sự chia cắt này tạo nên một cấu trúc dữ liệu được gọi là cây BSP.&lt;/p&gt;

&lt;p&gt;BSP có nhiều ứng dụng, đặc biệt là trong các bài toán về đồ hoạ. Điển hình như trong bài toán dựng hình (xác định đối tượng nào được dựng trong khung hình từ góc một góc nhìn nào đó), trong hệ thống CAD, phát hiện va chạm trong robotics, cũng như trong các bài toán chứa các cấu trúc không gian phức tạp.&lt;/p&gt;

&lt;p&gt;Trong trường hợp tổng quát, cây BSP, từ mỗi node của mình sẽ chia không gian thành hai nửa siêu phẳng, từ mỗi nửa siêu phẳng đó sẽ tiếp tục được chia cắt thành các nửa siêu phẳng nhỏ hơn sao cho những node lá cuối cùng sẽ chứa 1 đối tượng mà thuộc không gian. Có thể thấy cây BSP là trường hợp tổng quát của cây &lt;a href=&#34;https://en.wikipedia.org/wiki/K-d_tree&#34;&gt;k-d&lt;/a&gt;, và &lt;a href=&#34;https://en.wikipedia.org/wiki/Quadtree&#34;&gt;Quadtree&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;v-d-1&#34;&gt;Ví dụ&lt;/h2&gt;

&lt;p&gt;Để đơn giản bài toán ta xét trường hợp mặt phẳng với dữ liệu đầu vào là tập các đoạn thẳng sao cho từng cặp trong tập không giao nhau $S=\{s_1, s_2, \dots, s_n\}$, output của bài toán là một cây BSP mà mỗi vùng trong mỗi node lá chỉ chứa 1 một đoạn thẳng.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Chọn ngẫu nhiên (theo phân phối đều) một hoán vị $\pi$ trong tập hoá vị của $\{1, 2, \dots, n \}$ (gồm $n!$ phần tử).&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Tồn tại một vùng chứa nhiều hơn 1 đoạn thẳng:&lt;/p&gt;

    &lt;p&gt;2.a Cắt vùng này bởi &lt;em&gt;đường thẳng&lt;/em&gt; $l(s_i)$ trong đó $i$ là phần tử đầu tiên trong hoán vị (ở đây đường thẳng $l$ sẽ chứa $s_i$) $\pi$ sao cho $s_i$ cắt vùng đang xét.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;phn-tch&#34;&gt;Phân tích&lt;/h2&gt;

&lt;p&gt;Gọi biến $X_{ij}$ là biến ngẫu nhiên và $X_{ij}=1$ khi đường thẳng chứa $s_i$ cắt $s_j$ trong một vòng gọi đệ quy nào đó, $X_{ij}=0$ trong trường hợp ngược lại.&lt;/p&gt;

&lt;p&gt;Ở đây ta muốn xét xem kì vọng số lần thuật toán này cắt phải một đoạn thẳng trong tập đầu vào $S$.&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\mathbf{E} (X) = \mathbf{E} \left [ \sum_{i=1}^{n} \sum_{i=1}^{n} X _ {ij} \right ]&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;=  \sum_{i=1}^{n} \sum_{i=1}^{n} \mathbf{E} [X _ {ij} ]&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;=  \sum_{i=1}^{n} \sum_{i=1}^{n} Pr [X _ {ij} = 1 ]&lt;/script&gt;

&lt;p&gt;Bài toán được quy về việc tính xác suất $Pr[X_{ij}=1]$. Gọi $t$ là giao điểm của $s_i$ và $s_j$, $index(i,j)=t$ nếu $s_i$ cắt $t-1$ đoạn thẳng trước khi giao với $s_j$, như ví dụ bên dưới $s_{ij}=4$. Trường hợp hai đoạn thẳng không cắt nhau thì $S_{ij}=\infty$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/kyaZ5CL.png&#34; alt=&#34;Ví dụ về giá trị index(i, j)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bởi đường thẳng chứa $s_i$ bất kì có thể tiến vô cùng về hai phía nên tồn tại hai đoạn sao cho $index(s_i, s_j) = index(s_i, s_k)$. Nếu $index(s_i, s_j)=t$ ta gọi $s_{i1}, s_{i2}, \dots, s_{it}$ là những đoạn thẳng mà $s_i$ sẽ cắt trước khi giao với $s_j$, xác suất đề sự kiện này xảy ra là $\frac{1}{t+1}$&lt;/p&gt;

&lt;p&gt;Cho một đoạn $s_k$ cố định và $m \in \{0, 1, 2, dots, n-2 \}$ tồn tại tối đa hai đoạn thẳng $s_l$ sao cho $index(s_l, s_k)=m$&lt;/p&gt;

&lt;p&gt;Cận trên được tính như sau:&lt;/p&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\mathbf{E}[X] = \sum_{i=1}^{n} \sum_{j=1}^{n} Pr [X _ {ij} = 1 ]&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\leq \sum_{i=1}^{n} \sum_{j=1}^{n} \frac{1}{index(i, j) + 1}&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;\sum_{i=1}^{n} \sum_{k=2}^{n} \frac{2}{k}&lt;/script&gt;

&lt;script type=&#34;math/tex; mode=display&#34;&gt;= 2n \ln n&lt;/script&gt;

&lt;h1 id=&#34;ti-liu-tham-kho&#34;&gt;Tài liệu tham khảo.&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&#34;http://www.csee.wvu.edu/~ksmani/courses/fa01/random/lecnotes/lecture2.pdf&#34;&gt;Introduction to Randomized Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&#34;http://cs.au.dk/~gudmund/Documents/randompearlnotes.pdf&#34;&gt;Randomised Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


  &lt;/div&gt;

  &lt;div class=&#34;date&#34;&gt;
    Written on July 10, 2016
  &lt;/div&gt;

  
&lt;div class=&#34;comments&#34;&gt;
	&lt;div id=&#34;disqus_thread&#34;&gt;&lt;/div&gt;
	&lt;script type=&#34;text/javascript&#34;&gt;

	    var disqus_shortname = &#39;httpdangkhoasdcgithubio&#39;;

	    (function() {
	        var dsq = document.createElement(&#39;script&#39;); dsq.type = &#39;text/javascript&#39;; dsq.async = true;
	        dsq.src = &#39;//&#39; + disqus_shortname + &#39;.disqus.com/embed.js&#39;;
	        (document.getElementsByTagName(&#39;head&#39;)[0] || document.getElementsByTagName(&#39;body&#39;)[0]).appendChild(dsq);
	    })();

	&lt;/script&gt;
	&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&#34;http://disqus.com/?ref_noscript&#34;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;
&lt;/div&gt;

&lt;/article&gt;

    &lt;/div&gt;

    &lt;div class=&#34;wrapper-footer&#34;&gt;
      &lt;div class=&#34;container&#34;&gt;
        &lt;footer class=&#34;footer&#34;&gt;
          
&lt;a href=&#34;mailto:letandangkhoa@gmail.com&#34;&gt;&lt;i class=&#34;svg-icon email&#34;&gt;&lt;/i&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.facebook.com/dangkhoasdc&#34;&gt;&lt;i class=&#34;svg-icon facebook&#34;&gt;&lt;/i&gt;&lt;/a&gt;

&lt;a href=&#34;https://github.com/dangkhoasc&#34;&gt;&lt;i class=&#34;svg-icon github&#34;&gt;&lt;/i&gt;&lt;/a&gt;



&lt;a href=&#34;http://dangkhoasdc.github.io/feed.xml&#34;&gt;&lt;i class=&#34;svg-icon rss&#34;&gt;&lt;/i&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.twitter.com/dksdc&#34;&gt;&lt;i class=&#34;svg-icon twitter&#34;&gt;&lt;/i&gt;&lt;/a&gt;



        &lt;/footer&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    
	&lt;!-- Google Analytics --&gt;
	&lt;script&gt;
		(function(i,s,o,g,r,a,m){i[&#39;GoogleAnalyticsObject&#39;]=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,&#39;script&#39;,&#39;//www.google-analytics.com/analytics.js&#39;,&#39;ga&#39;);

		ga(&#39;create&#39;, &#39;UA-2381283-3&#39;, &#39;auto&#39;);
		ga(&#39;send&#39;, &#39;pageview&#39;, {
		  &#39;page&#39;: &#39;/randalgs-examples/&#39;,
		  &#39;title&#39;: &#39;Các ví dụ về thuật toán ngẫu nhiên&#39;
		});
	&lt;/script&gt;
	&lt;!-- End Google Analytics --&gt;


  &lt;/body&gt;
&lt;/html&gt;
</description>
    </item>
    
  </channel>
</rss>
