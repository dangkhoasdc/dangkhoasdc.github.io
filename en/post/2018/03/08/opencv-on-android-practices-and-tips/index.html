<!DOCTYPE html>
<html lang="vi">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>OpenCV on Android: practices and tips | Dang-Khoa&#39;s blog</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
      

    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">OpenCV on Android: practices and tips</span></h1>

<h2 class="date">2018/03/08</h2>
</div>

<main>


<h1 id="transfer-mat-objects-from-android-to-ndk">Transfer MAT objects from Android to NDK</h1>

<p>The main idea is to use the address of an MAT object in order to manipulate
the data.</p>

<p>Basically, we have a function playing as a bridge between Java APIs and NDK:</p>

<pre><code class="language-java">public native void function_name(long matAddress);
</code></pre>

<p>To call the function, we use Mat&rsquo;s address by calling <code>getNativeObjAddr()</code>.
All computations in NDK will affect the content of MAT in both Java and
NDK layers.</p>

<p>In the NDK code, to use <code>cv::Mat</code> object regarding <code>java Mat</code>, we can use
<code>static_cast</code>:</p>

<pre><code class="language-cpp">
Mat&amp; im = *(static_cast&lt;Mat*&gt;(addrImg));
</code></pre>

<h2 id="notes">Notes</h2>

<p>There is a huge different in image channels between <code>Java OpenCV</code> and <code>NDK OpenCV</code>.
When we decode the path or file to a bitmap in Java, we have to convert
the bitmap to <code>ARGB_8888</code> color channel, otherwise it does not work. Actually,
it also can work on <code>RGB_565</code> but for some reasons I can not remember, I always
use <code>ARGB_8888</code> in the project.</p>

<pre><code class="language-java">Bitmap bm32_image = bm.copy(Bitmap.Config.ARGB_8888, true);
</code></pre>

<p>To manipulate the image correctly in NDK, we should covert it to the normal
RGB channel, otherwise sometimes we get some bugs making us frustrating.</p>

<pre><code class="language-java">// convert ARGB_8888 to RGB
Mat im = new Mat();
Mat rgb_im = new Mat();
Utils.bitmapToMat(bm32_image, im);
Imgproc.cvtcolor(im, rgb_im, Imgproc.COLOR_RGBA2RGB, 3);

function_name(rgb_im.getNativeObjAddr());
</code></pre>

<p>Other practice is to put some assertions in NDK code to make sure that we the
use the correct format for the input.</p>

<h1 id="opencv-s-camera">OpenCV&rsquo;s Camera</h1>

<p>OpenCV supports 3 types of camera:</p>

<ul>
<li><code>CameraBridgeViewBase</code>.</li>
<li><code>JavaCameraView</code>.</li>
<li><code>CameraSurfaceGLView</code>.</li>
</ul>

<h2 id="javacameraview">JavaCameraView</h2>

<ol>
<li>Create the layout of the camera. For example, we can put the following lines
to the Activity xml file:</li>
</ol>

<pre><code class="language-xml">&lt;org.opencv.android.JavaCameraView
    android:layout_width=&quot;fill_parent&quot;
    android:layout_height=&quot;fill_parent&quot;
    android:id=&quot;@+id/opencvcamera_view&quot;
&gt;&lt;/org.opencv.android.JavaCameraView&gt;
</code></pre>

<ol>
<li>Next, in the activity which controls the camera, we have to implement
required methods from the <code>CvCameraViewLisener2</code>. There 3 methods are:</li>
</ol>

<ul>
<li><code>onCameraViewStarted</code>.</li>
<li><code>onCameraViewStopped</code>.</li>
<li><code>onCameraFrame</code>.</li>
</ul>

<p>Prior to processing the camera, we need to initialize the variable holding
callbacks of three aforementioned methods:</p>

<pre><code class="language-java">private CameraBridgeViewBase mOpenCVCamera;

</code></pre>

<p>On the <code>onCreate</code> method:</p>

<pre><code class="language-java">
    mOpenCVCamera = (CameraBridgeViewBase) findViewById(R.id.opencvcamera_view);
    mOpenCVCamera.setVisibility(CameraBridgeViewBase.VISIBLE);
    mOpenCVCamera.setCvCameraViewListener(this);
</code></pre>

<p>Next, we implement 3 required methods:</p>

<pre><code class="language-java">    @Override
    public void onCameraViewStarted(int width, int height) {
        // initialize images, variables, settings
    }

    @Override
    public void onCameraViewStopped() {
        // release the resources
    }

    @Override
    public Mat onCameraFrame(CameraBridgeViewBase.CvCameraViewFrame inputFrame) {
        // retrieve the frame from `inputFrame`
        // - the grayscale frame by imputFrame.gray()
        // - the RGBA frame by inputFrame.rgba()
        Mat im = inputFrame.rgba();

        // do things
        // postprocess: convert back to the RGBA image
        return im; // `im` will show in the UI
    }

</code></pre>

<p>Noting that OpenCV&rsquo;s Camera is not able to set the portrait mode. One workaround
is to turn the Activity to <code>landscape</code> by putting the following line inside tag <code>Activity</code>
in <code>AndroidManifest.xml</code></p>

<pre><code class="language-xml">android:screenOrientation=&quot;landscape&quot;
</code></pre>

<h1 id="data-manipulation">Data Manipulation</h1>

<h3 id="unsigned-char-mat"><code>unsigned char</code> Mat</h3>

<p>It is troublesome when we want to assign a value of 255 to an <code>unsigned char</code> Mat
because this language does not support <code>unsigned char</code> as a primitive type.
One workaround is to allocate a <code>16S</code> Mat, manipulate on that matrix, and
finally convert to <code>8U</code>.</p>

<h3 id="point2f-and-point">Point2f and Point</h3>

<p>To convert <code>MatOfPoint</code> to <code>MatOfPoint2f</code>, we use the constructor:</p>

<pre><code class="language-java">MatOfPoint matofpoint = new MatOfPoint(matofpoint2f.toArray());
</code></pre>

<h2 id="accessing-the-pixel-values">Accessing the pixel values</h2>

<p>In order to retrieve and assign pixel value, we use the getter/setter from <code>Mat</code>.</p>

<pre><code class="language-java">short[] pixel = new short[nchannels];

m.get(i, j, pixel); // retrieve pixel values at (i, j)
// in this example, the pixel has 3 channels
pixel[0] = 255;
pixel[1] = 0;
pixel[2] = 125;
m.set(i, j, pixel);
</code></pre>

</main>

  <footer>
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
onload='renderMathInElement(document.body,{
  delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false}
  ]});'></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-2381283-3', 'auto');
	
	ga('send', 'pageview');
}
</script>


  
  <hr/>
  &copy; <a href="https://dkhoa.dev">Dang-Khoa</a> 2017 &ndash; 2019 | <a href="https://github.com/dangkhoasdc">Github</a> | <a href="https://twitter.com/dksdc">Twitter</a>
  
  </footer>
  </body>
</html>

