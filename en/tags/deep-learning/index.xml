<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deep learning on Dang-Khoa&#39;s blog</title>
    <link>http://dangkhoasdc.github.io/en/tags/deep-learning/</link>
    <description>Recent content in deep learning on Dang-Khoa&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>vi</language>
    <lastBuildDate>Tue, 11 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://dangkhoasdc.github.io/en/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sampling techniques for Partially Annotated Detection</title>
      <link>http://dangkhoasdc.github.io/en/post/2019/06/11/sampling-techniques-for-partially-annotated-detection/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://dangkhoasdc.github.io/en/post/2019/06/11/sampling-techniques-for-partially-annotated-detection/</guid>
      <description>In this post, I will discuss two papers that try to handle the partially annotated datasets. Let talk a bit about why we care about missing annotations in detection. Firstly, labelling box is difficult. Increasing the size of taxonomy also exponentially increase the difficulty of the task. Secondly, Suppose that originally we have a training dataset with 20 categories, later, we want to add 10 more new categories into the model.</description>
    </item>
    
    <item>
      <title>[WIP] Libra R-CNN: Paper review and comments</title>
      <link>http://dangkhoasdc.github.io/en/post/2019/06/03/wip-libra-r-cnn-paper-review-and-comments/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://dangkhoasdc.github.io/en/post/2019/06/03/wip-libra-r-cnn-paper-review-and-comments/</guid>
      <description>Regarding the object detection problem, it seems like the community pays less attention to training pipeline than other tasks such as network design, inference improvement. This paper investigates the current problem of the CNN detection models. They consider the imbalance phenomenon, which is composed of 3 levels:
 Sample level. Feature level. Objective level.  They basically are 3 corresponding major components of a detection model: feature extraction, region proposals, and predictors.</description>
    </item>
    
    <item>
      <title>Groupnorm: Paper, review and implementations</title>
      <link>http://dangkhoasdc.github.io/en/post/2019/05/28/groupnorm-paper-review-and-implementations/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://dangkhoasdc.github.io/en/post/2019/05/28/groupnorm-paper-review-and-implementations/</guid>
      <description>After several tries, I have found out that GroupNorm works suprisingly well on detection models. Just turn on the GroupNorm of FPN and I can get an improvement with a large margin. Going further, I want to replace Batchnorm of the backbone with GroupNorm and see how I can utilize this layer in other networks.
Paper: overview and comments Criticism about BatchNorm It does not work well on models trained with small batches.</description>
    </item>
    
  </channel>
</rss>